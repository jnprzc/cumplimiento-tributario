"""
Scraper para obtener datos reales del RUES (Confec√°maras)
"""

import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime

class RUESScraper:
    """
    Clase para hacer scraping del RUES de Confec√°maras
    """
    
    def __init__(self):
        self.base_url = "https://www.rues.org.co"
        self.consulta_url = f"{self.base_url}/RM/ConsultaNIT"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Content-Type': 'application/x-www-form-urlencoded',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        }
    
    def consultar(self, nit):
        """
        Consulta informaci√≥n de una empresa por NIT
        
        Args:
            nit (str): NIT de 9 d√≠gitos
            
        Returns:
            dict: Datos de la empresa o None si hay error
        """
        try:
            # Hacer la petici√≥n POST
            payload = {'nit': nit}
            response = requests.post(
                self.consulta_url, 
                data=payload, 
                headers=self.headers, 
                timeout=15
            )
            
            if response.status_code != 200:
                return None
            
            # Parsear HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Extraer datos
            datos = self._extraer_datos(soup, nit)
            
            return datos
            
        except Exception as e:
            print(f"Error en consulta RUES: {e}")
            return None
    
    def _extraer_datos(self, soup, nit):
        """
        Extrae informaci√≥n del HTML del RUES
        
        Args:
            soup: BeautifulSoup object
            nit: NIT consultado
            
        Returns:
            dict: Datos extra√≠dos
        """
        datos = {
            'nit': nit,
            'razon_social': self._extraer_razon_social(soup),
            'estado': self._extraer_estado(soup),
            'municipio': self._extraer_municipio(soup),
            'departamento': self._extraer_departamento(soup),
            'actividad_principal': self._extraer_actividad(soup),
            'fecha_matricula': self._extraer_fecha_matricula(soup),
            'ultima_renovacion': self._extraer_ultima_renovacion(soup),
            'tipo_sociedad': self._extraer_tipo_sociedad(soup),
            'camara': self._extraer_camara(soup)
        }
        
        return datos
    
    def _extraer_texto_por_label(self, soup, label):
        """
        Busca un valor en el HTML basado en su label
        """
        try:
            # Buscar diferentes patrones comunes
            patterns = [
                # Patr√≥n 1: <strong>Label:</strong> Valor
                soup.find('strong', string=re.compile(label, re.IGNORECASE)),
                # Patr√≥n 2: <td>Label</td><td>Valor</td>
                soup.find('td', string=re.compile(label, re.IGNORECASE))
            ]
            
            for pattern in patterns:
                if pattern:
                    # Intentar obtener el siguiente elemento
                    siguiente = pattern.find_next_sibling()
                    if siguiente:
                        return siguiente.get_text(strip=True)
                    
                    # O el elemento padre y su siguiente hermano
                    parent = pattern.parent
                    if parent:
                        siguiente = parent.find_next_sibling()
                        if siguiente:
                            return siguiente.get_text(strip=True)
            
            return "No disponible"
            
        except:
            return "No disponible"
    
    def _extraer_razon_social(self, soup):
        """Extrae la raz√≥n social"""
        # Buscar en diferentes posibles ubicaciones
        posibles = [
            soup.find('td', string=re.compile('Raz√≥n Social', re.IGNORECASE)),
            soup.find('strong', string=re.compile('Raz√≥n Social', re.IGNORECASE)),
            soup.find(string=re.compile('Raz√≥n Social:', re.IGNORECASE))
        ]
        
        for pos in posibles:
            if pos:
                # Obtener el siguiente td o span
                siguiente = pos.find_next('td') if hasattr(pos, 'find_next') else None
                if siguiente:
                    return siguiente.get_text(strip=True)
        
        return "No disponible"
    
    def _extraer_estado(self, soup):
        """Extrae el estado de la matr√≠cula"""
        estado = self._extraer_texto_por_label(soup, 'Estado')
        
        # Normalizar
        if 'activ' in estado.lower():
            return 'ACTIVA'
        elif 'inactiv' in estado.lower():
            return 'INACTIVA'
        elif 'cancelad' in estado.lower():
            return 'CANCELADA'
        
        return estado
    
    def _extraer_municipio(self, soup):
        """Extrae el municipio"""
        return self._extraer_texto_por_label(soup, 'Municipio')
    
    def _extraer_departamento(self, soup):
        """Extrae el departamento"""
        return self._extraer_texto_por_label(soup, 'Departamento')
    
    def _extraer_actividad(self, soup):
        """Extrae la actividad econ√≥mica principal"""
        actividad = self._extraer_texto_por_label(soup, 'Actividad')
        if not actividad or actividad == "No disponible":
            actividad = self._extraer_texto_por_label(soup, 'CIIU')
        return actividad
    
    def _extraer_fecha_matricula(self, soup):
        """Extrae la fecha de matr√≠cula"""
        fecha = self._extraer_texto_por_label(soup, 'Fecha.*Matr√≠cula')
        return self._normalizar_fecha(fecha)
    
    def _extraer_ultima_renovacion(self, soup):
        """Extrae la √∫ltima fecha de renovaci√≥n"""
        fecha = self._extraer_texto_por_label(soup, 'Renovaci√≥n')
        if not fecha or fecha == "No disponible":
            fecha = self._extraer_texto_por_label(soup, '√öltima.*Renovaci√≥n')
        return self._normalizar_fecha(fecha)
    
    def _extraer_tipo_sociedad(self, soup):
        """Extrae el tipo de sociedad"""
        return self._extraer_texto_por_label(soup, 'Tipo.*Sociedad')
    
    def _extraer_camara(self, soup):
        """Extrae la c√°mara de comercio"""
        return self._extraer_texto_por_label(soup, 'C√°mara')
    
    def _normalizar_fecha(self, fecha_str):
        """
        Normaliza fechas a formato ISO (YYYY-MM-DD)
        """
        if not fecha_str or fecha_str == "No disponible":
            return "No disponible"
        
        try:
            # Intentar parsear diferentes formatos comunes
            formatos = [
                '%d/%m/%Y',
                '%d-%m-%Y',
                '%Y-%m-%d',
                '%d de %B de %Y'
            ]
            
            for formato in formatos:
                try:
                    fecha = datetime.strptime(fecha_str, formato)
                    return fecha.strftime('%Y-%m-%d')
                except:
                    continue
            
            return fecha_str
            
        except:
            return fecha_str

# Funci√≥n helper para uso f√°cil
def consultar_rues(nit):
    """
    Funci√≥n simple para consultar el RUES
    
    Args:
        nit (str): NIT de la empresa
        
    Returns:
        dict: Datos de la empresa
    """
    scraper = RUESScraper()
    return scraper.consultar(nit)


# Test
if __name__ == "__main__":
    print("="*60)
    print("üîç TEST: RUES Scraper")
    print("="*60)
    
    # Probar con NITs conocidos
    nits_prueba = [
        "890903938",  # Bancolombia
        "860034313",  # Ecopetrol
    ]
    
    for nit in nits_prueba:
        print(f"\nüìä Consultando NIT: {nit}")
        print("-"*60)
        
        datos = consultar_rues(nit)
        
        if datos:
            print("‚úÖ Datos obtenidos:")
            for key, value in datos.items():
                print(f"   {key}: {value}")
        else:
            print("‚ùå No se pudieron obtener datos")
    
    print("\n" + "="*60)
    print("‚úÖ Test completado")
    print("="*60)